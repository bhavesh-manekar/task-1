{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83258a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Collecting textstat\n",
      "  Downloading textstat-0.7.7-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cmudict (from textstat)\n",
      "  Downloading cmudict-1.0.33-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from textstat) (69.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: importlib-metadata>=5 in /opt/anaconda3/lib/python3.12/site-packages (from cmudict->textstat) (7.0.1)\n",
      "Requirement already satisfied: importlib-resources>=5 in /opt/anaconda3/lib/python3.12/site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata>=5->cmudict->textstat) (3.17.0)\n",
      "Downloading textstat-0.7.7-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading cmudict-1.0.33-py3-none-any.whl (939 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\n",
      "Successfully installed cmudict-1.0.33 pyphen-0.17.2 textstat-0.7.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk scikit-learn textstat requests beautifulsoup4 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff4a4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sanjayjangid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanjayjangid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXT SUMMARIZER ===\n",
      "Paste your article below. Press Enter twice to summarize.\n",
      "\n",
      "\n",
      "=== SUMMARY ===\n",
      "At each grid point the model predicts five Earthsurface variables  including temperature wind speed and direction and mean sealevel pressure  and six atmospheric variables at each of 37 levels of altitude including specific humidity wind speed and direction and temperature. While GraphCasts training was computationally intensive the resulting forecasting model is highly efficient. In a comprehensive performance evaluation against the goldstandard deterministic system HRES GraphCast provided more accurate predictions on more than 90 of 1380 test variables and forecast lead times see our Science paper for details.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import heapq\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess the text\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def calculate_word_frequency(sentences, stop_words):\n",
    "    \"\"\"Calculate normalized word frequency\"\"\"\n",
    "    word_freq = Counter()\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        for word in words:\n",
    "            if word.isalpha() and word not in stop_words:\n",
    "                word_freq[word] += 1\n",
    "    max_freq = max(word_freq.values(), default=1)\n",
    "    for word in word_freq:\n",
    "        word_freq[word] /= max_freq\n",
    "    return word_freq\n",
    "\n",
    "def score_sentences(sentences, word_freq):\n",
    "    \"\"\"Assign a score to each sentence\"\"\"\n",
    "    scores = {}\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        score = sum(word_freq.get(word, 0) for word in words if word.isalpha())\n",
    "        if len(words) > 0:\n",
    "            scores[sentence] = score / len(words)\n",
    "    return scores\n",
    "\n",
    "def summarize(text, num_sentences=3):\n",
    "    \"\"\"Return summary with top N scored sentences\"\"\"\n",
    "    text = clean_text(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_freq = calculate_word_frequency(sentences, stop_words)\n",
    "    sentence_scores = score_sentences(sentences, word_freq)\n",
    "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    return ' '.join([s for s in sentences if s in summary_sentences])\n",
    "\n",
    "# === Example usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== TEXT SUMMARIZER ===\")\n",
    "    print(\"Paste your article below. Press Enter twice to summarize.\\n\")\n",
    "\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line.strip() == \"\" and lines:\n",
    "            break\n",
    "        lines.append(line)\n",
    "    input_text = \"\\n\".join(lines)\n",
    "\n",
    "    result = summarize(input_text, num_sentences=3)\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba769d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
